{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f04ac0a1550>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/databricks/spark-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data structure name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "customSchema = StructType([ \n",
    "        StructField(\"Date\", StringType(), True), \\\n",
    "        StructField(\"Open\", DoubleType(), True), \\\n",
    "        StructField(\"High\", DoubleType(), True), \\\n",
    "        StructField(\"Low\", DoubleType(), True), \\\n",
    "        StructField(\"close\", DoubleType(), True), \\\n",
    "        StructField(\"Volume_n\", DoubleType(), True), \\\n",
    "        StructField(\"Volume_m\", DoubleType(), True), \\\n",
    "        StructField(\"return\", DoubleType(), True), \\\n",
    "        StructField(\"PE\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read \\\n",
    ".format('com.databricks.spark.csv') \\\n",
    ".options(header='true') \\\n",
    ".load('1101.csv', schema = customSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+----+-----+--------+--------+------+-----+\n",
      "|    Date| Open| High| Low|close|Volume_n|Volume_m|return|   PE|\n",
      "+--------+-----+-----+----+-----+--------+--------+------+-----+\n",
      "|1998/1/3|12.84|12.84|12.6| 12.6|  1624.0| 62200.0| -1.81|26.76|\n",
      "+--------+-----+-----+----+-----+--------+--------+------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- Volume_n: double (nullable = true)\n",
      " |-- Volume_m: double (nullable = true)\n",
      " |-- return: double (nullable = true)\n",
      " |-- PE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newDF = df.drop(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-----+--------+--------+------+-----+\n",
      "| Open| High|  Low|close|Volume_n|Volume_m|return|   PE|\n",
      "+-----+-----+-----+-----+--------+--------+------+-----+\n",
      "|12.84|12.84| 12.6| 12.6|  1624.0| 62200.0| -1.81|26.76|\n",
      "| 12.6| 12.7|12.44|12.44|  4952.0|187464.0| -1.32|26.41|\n",
      "|12.44|12.44|12.21|12.24|  3408.0|126192.0|  -1.6|25.99|\n",
      "+-----+-----+-----+-----+--------+--------+------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume_n</th>\n",
       "      <th>Volume_m</th>\n",
       "      <th>return</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.84</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.60</td>\n",
       "      <td>12.60</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>62200.0</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>26.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.60</td>\n",
       "      <td>12.70</td>\n",
       "      <td>12.44</td>\n",
       "      <td>12.44</td>\n",
       "      <td>4952.0</td>\n",
       "      <td>187464.0</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>26.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.44</td>\n",
       "      <td>12.44</td>\n",
       "      <td>12.21</td>\n",
       "      <td>12.24</td>\n",
       "      <td>3408.0</td>\n",
       "      <td>126192.0</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>25.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.27</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.01</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3207.0</td>\n",
       "      <td>117772.0</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>25.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.97</td>\n",
       "      <td>12.11</td>\n",
       "      <td>11.87</td>\n",
       "      <td>11.87</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>110927.0</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>25.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Open   High    Low  close  Volume_n  Volume_m  return     PE\n",
       "0  12.84  12.84  12.60  12.60    1624.0   62200.0   -1.81  26.76\n",
       "1  12.60  12.70  12.44  12.44    4952.0  187464.0   -1.32  26.41\n",
       "2  12.44  12.44  12.21  12.24    3408.0  126192.0   -1.60  25.99\n",
       "3  12.27  12.40  12.01  12.01    3207.0  117772.0   -1.90  25.49\n",
       "4  11.97  12.11  11.87  11.87    3072.0  110927.0   -1.11  25.21"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = newDF.toPandas().head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12.84\n",
       "1    12.60\n",
       "2    12.44\n",
       "3    12.27\n",
       "4    11.97\n",
       "Name: Open, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Open']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting pandas dataframes to spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/32966344/converting-pandas-dataframes-to-spark-dataframe-in-zeppelin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f048e762f10>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlCtx = SQLContext(sc)\n",
    "sqlCtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-----+--------+--------+------+-----+\n",
      "| Open| High|  Low|close|Volume_n|Volume_m|return|   PE|\n",
      "+-----+-----+-----+-----+--------+--------+------+-----+\n",
      "|12.84|12.84| 12.6| 12.6|  1624.0| 62200.0| -1.81|26.76|\n",
      "| 12.6| 12.7|12.44|12.44|  4952.0|187464.0| -1.32|26.41|\n",
      "|12.44|12.44|12.21|12.24|  3408.0|126192.0|  -1.6|25.99|\n",
      "|12.27| 12.4|12.01|12.01|  3207.0|117772.0|  -1.9|25.49|\n",
      "|11.97|12.11|11.87|11.87|  3072.0|110927.0| -1.11|25.21|\n",
      "+-----+-----+-----+-----+--------+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = sqlCtx.createDataFrame(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
