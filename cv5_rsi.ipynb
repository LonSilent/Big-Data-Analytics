{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Create features rsi : Time taken = 457.395052 second\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "import time\n",
    "data = []\n",
    "datapath = '/home/bigdatas16/1101.csv'\n",
    "data = pd.read_csv(datapath)\n",
    " \n",
    "# Close Rise Ratio 漲幅比\n",
    "def RR(data):\n",
    "    dataList = range(data['Date'].size)\n",
    "    tmpList = []\n",
    "    #tmpList.append(0)\n",
    "\n",
    "    for item in dataList:\n",
    "        # 防止 第一筆data沒有更舊的\n",
    "        if item - 1 >=0:\n",
    "            # (今日收盤價 - 昨日收盤價)/昨日收盤價\n",
    "            tmp = (data['Close'][item]-data['Close'][item-1])/data['Close'][item-1]*100\n",
    "            tmpList.append(tmp)\n",
    "        elif item - 1 < 0:\n",
    "            tmp = 0\n",
    "            tmpList.append(tmp)\n",
    "        \n",
    "    # 前day 沒data會出現NA\n",
    "    tmpSeries = pd.Series(tmpList)\n",
    "    # create  RR 欄位\n",
    "    data['RR']=tmpSeries\n",
    "RR(data)\n",
    "# 相對強弱指標(RSI) 建議6\n",
    "def RSI(data,day):\n",
    "    dataList = range(data['Date'].size)\n",
    "    tmpList = []\n",
    "    #tmpList.append(0)\n",
    "    for item in dataList:\n",
    "        # 防止前day沒有data\n",
    "        if item - day >= 0:\n",
    "            # 6日RSI=100*6日內收盤上漲總幅度平均值 / (6日內收盤上漲總幅度平均值 - 6日內收盤下跌總幅度平均值)   \n",
    "            bolRise = data['RR'][item-day+1-1:item+1-1] > 0\n",
    "            #print(bolRise)\n",
    "            meanRise = data['RR'][item-day+1-1:item+1-1][bolRise].mean()\n",
    "            \n",
    "            if meanRise > 0:\n",
    "                meanRise = meanRise\n",
    "            else:\n",
    "                meanRise = 0\n",
    "                \n",
    "            bolDesc = data['RR'][item-day+1-1:item+1-1] < 0\n",
    "            #print(bolDesc)\n",
    "            meanDesc = data['RR'][item-day+1-1:item+1-1][bolDesc].mean() \n",
    "                \n",
    "            if meanDesc < 0:\n",
    "                meanDesc = meanDesc\n",
    "            else:\n",
    "                meanDesc = 0\n",
    "                \n",
    "            #print(meanRise) \n",
    "            #print(meanDesc)\n",
    "\n",
    "            if meanRise == 0 and meanDesc == 0:\n",
    "                tmp = 0.50\n",
    "            else:    \n",
    "                tmp = 100 * ((meanRise*1.0) / (meanRise - meanDesc))\n",
    "            #print(tmp)\n",
    "            tmpList.append(tmp)\n",
    "            \n",
    "        elif item - day < 0:\n",
    "            tmp = 0\n",
    "            tmpList.append(tmp)              \n",
    "    # 前day 沒data會出現NA\n",
    "    tmpSeries = pd.Series(tmpList)\n",
    "    \n",
    "    # create  RSI 欄位\n",
    "    data['RSI'+str(day)] = tmpSeries\n",
    "\n",
    "# High Rise Ratio 漲幅比\n",
    "def RR_H(data):\n",
    "    dataList = range(data['Date'].size)\n",
    "    tmpList = []\n",
    "    #tmpList.append(0)\n",
    "\n",
    "    for item in dataList:\n",
    "        # 防止 第一筆data沒有更舊的\n",
    "        if item - 1 >=0:\n",
    "            # (今日收盤價 - 昨日收盤價)/昨日收盤價\n",
    "            tmp = (data['High'][item]-data['High'][item-1])/data['High'][item-1]*100\n",
    "            tmpList.append(tmp)\n",
    "        elif item - 1 < 0:\n",
    "            tmp = 0\n",
    "            tmpList.append(tmp)\n",
    "        \n",
    "    # 前day 沒data會出現NA\n",
    "    tmpSeries = pd.Series(tmpList)\n",
    "    # create  RR 欄位\n",
    "    data['RR_H']=tmpSeries\n",
    "RR_H(data)\n",
    "# 相對強弱指標(RSI) 建議6\n",
    "def RSI_H(data,day):\n",
    "    dataList = range(data['Date'].size)\n",
    "    tmpList = []\n",
    "    #tmpList.append(0)\n",
    "    for item in dataList:\n",
    "        # 防止前day沒有data\n",
    "        if item - day >= 0:\n",
    "            bolRise = data['RR_H'][item-day+1-1:item+1-1] > 0\n",
    "            #print(bolRise)\n",
    "            meanRise = data['RR_H'][item-day+1-1:item+1-1][bolRise].mean()\n",
    "            \n",
    "            if meanRise > 0:\n",
    "                meanRise = meanRise\n",
    "            else:\n",
    "                meanRise = 0\n",
    "                \n",
    "            bolDesc = data['RR_H'][item-day+1-1:item+1-1] < 0\n",
    "            #print(bolDesc)\n",
    "            meanDesc = data['RR_H'][item-day+1-1:item+1-1][bolDesc].mean() \n",
    "                \n",
    "            if meanDesc < 0:\n",
    "                meanDesc = meanDesc\n",
    "            else:\n",
    "                meanDesc = 0\n",
    "                \n",
    "            #print(meanRise) \n",
    "            #print(meanDesc)\n",
    "\n",
    "            if meanRise == 0 and meanDesc == 0:\n",
    "                tmp = 0.50\n",
    "            else:    \n",
    "                tmp = 100 * ((meanRise*1.0) / (meanRise - meanDesc))\n",
    "            #print(tmp)\n",
    "            tmpList.append(tmp)\n",
    "            \n",
    "        elif item - day < 0:\n",
    "            tmp = 0\n",
    "            tmpList.append(tmp)              \n",
    "    # 前day 沒data會出現NA\n",
    "    tmpSeries = pd.Series(tmpList)\n",
    "    \n",
    "    # create  RSI 欄位\n",
    "    data['RSI_H'+str(day)] = tmpSeries\n",
    "    \n",
    "# Volumn_n Rise Ratio 漲幅比\n",
    "def RR_V(data):\n",
    "    dataList = range(data['Date'].size)\n",
    "    tmpList = []\n",
    "    #tmpList.append(0)\n",
    "\n",
    "    for item in dataList:\n",
    "        # 防止 第一筆data沒有更舊的\n",
    "        if item - 1 >=0:\n",
    "            # (今日收盤價 - 昨日收盤價)/昨日收盤價\n",
    "            tmp = (data['Volume_m'][item]-data['Volume_m'][item-1])/data['Volume_m'][item-1]*100\n",
    "            tmpList.append(tmp)\n",
    "        elif item - 1 < 0:\n",
    "            tmp = 0\n",
    "            tmpList.append(tmp)\n",
    "        \n",
    "    # 前day 沒data會出現NA\n",
    "    tmpSeries = pd.Series(tmpList)\n",
    "    # create  RR 欄位\n",
    "    data['RR_V']=tmpSeries\n",
    "RR_V(data)   \n",
    "# 相對強弱指標(RSI) 建議6\n",
    "def RSI_V(data,day):\n",
    "    dataList = range(data['Date'].size)\n",
    "    tmpList = []\n",
    "    #tmpList.append(0)\n",
    "    for item in dataList:\n",
    "        # 防止前day沒有data\n",
    "        if item - day >= 0:\n",
    "            # 6日RSI=100*6日內收盤上漲總幅度平均值 / (6日內收盤上漲總幅度平均值 - 6日內收盤下跌總幅度平均值)   \n",
    "            bolRise = data['RR_V'][item-day+1-1:item+1-1] > 0\n",
    "            #print(bolRise)\n",
    "            meanRise = data['RR_V'][item-day+1-1:item+1-1][bolRise].mean()\n",
    "            \n",
    "            if meanRise > 0:\n",
    "                meanRise = meanRise\n",
    "            else:\n",
    "                meanRise = 0\n",
    "                \n",
    "            bolDesc = data['RR_V'][item-day+1-1:item+1-1] < 0\n",
    "            #print(bolDesc)\n",
    "            meanDesc = data['RR_V'][item-day+1-1:item+1-1][bolDesc].mean() \n",
    "                \n",
    "            if meanDesc < 0:\n",
    "                meanDesc = meanDesc\n",
    "            else:\n",
    "                meanDesc = 0\n",
    "                \n",
    "            #print(meanRise) \n",
    "            #print(meanDesc)\n",
    "\n",
    "            if meanRise == 0 and meanDesc == 0:\n",
    "                tmp = 0.50\n",
    "            else:    \n",
    "                tmp = 100 * ((meanRise*1.0) / (meanRise - meanDesc))\n",
    "            #print(tmp)\n",
    "            tmpList.append(tmp)\n",
    "            \n",
    "        elif item - day < 0:\n",
    "            tmp = 0\n",
    "            tmpList.append(tmp)              \n",
    "    # 前day 沒data會出現NA\n",
    "    tmpSeries = pd.Series(tmpList)\n",
    "    \n",
    "    # create  RSI 欄位\n",
    "    data['RSI_V'+str(day)] = tmpSeries\n",
    "    \n",
    "start = time.time()       \n",
    "for i in range(2,18):\n",
    "    RSI(data,i) \n",
    "for i in range(2,18):\n",
    "    RSI_V(data,i) \n",
    "for i in range(2,18):\n",
    "    RSI_H(data,i)\n",
    "end = time.time()\n",
    "print \"Create features rsi : Time taken = %f second\"%(end - start)\n",
    "\n",
    "data = data.drop(data.index[4620])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume_n</th>\n",
       "      <th>Volume_m</th>\n",
       "      <th>return</th>\n",
       "      <th>PE</th>\n",
       "      <th>RR</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI_H9</th>\n",
       "      <th>RSI_H10</th>\n",
       "      <th>RSI_H11</th>\n",
       "      <th>RSI_H12</th>\n",
       "      <th>RSI_H13</th>\n",
       "      <th>RSI_H14</th>\n",
       "      <th>RSI_H15</th>\n",
       "      <th>RSI_H16</th>\n",
       "      <th>RSI_H17</th>\n",
       "      <th>UP_DOWN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998/1/3</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.60</td>\n",
       "      <td>12.60</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>62200.0</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>26.76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998/1/5</td>\n",
       "      <td>12.60</td>\n",
       "      <td>12.70</td>\n",
       "      <td>12.44</td>\n",
       "      <td>12.44</td>\n",
       "      <td>4952.0</td>\n",
       "      <td>187464.0</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>26.41</td>\n",
       "      <td>-1.269841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998/1/6</td>\n",
       "      <td>12.44</td>\n",
       "      <td>12.44</td>\n",
       "      <td>12.21</td>\n",
       "      <td>12.24</td>\n",
       "      <td>3408.0</td>\n",
       "      <td>126192.0</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>-1.607717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998/1/7</td>\n",
       "      <td>12.27</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.01</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3207.0</td>\n",
       "      <td>117772.0</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>25.49</td>\n",
       "      <td>-1.879085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998/1/8</td>\n",
       "      <td>11.97</td>\n",
       "      <td>12.11</td>\n",
       "      <td>11.87</td>\n",
       "      <td>11.87</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>110927.0</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>25.21</td>\n",
       "      <td>-1.165695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date   Open   High    Low  Close  Volume_n  Volume_m  return     PE  \\\n",
       "0  1998/1/3  12.84  12.84  12.60  12.60    1624.0   62200.0   -1.81  26.76   \n",
       "1  1998/1/5  12.60  12.70  12.44  12.44    4952.0  187464.0   -1.32  26.41   \n",
       "2  1998/1/6  12.44  12.44  12.21  12.24    3408.0  126192.0   -1.60  25.99   \n",
       "3  1998/1/7  12.27  12.40  12.01  12.01    3207.0  117772.0   -1.90  25.49   \n",
       "4  1998/1/8  11.97  12.11  11.87  11.87    3072.0  110927.0   -1.11  25.21   \n",
       "\n",
       "         RR   ...     RSI_H9  RSI_H10  RSI_H11  RSI_H12  RSI_H13  RSI_H14  \\\n",
       "0  0.000000   ...        0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1 -1.269841   ...        0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2 -1.607717   ...        0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3 -1.879085   ...        0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4 -1.165695   ...        0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   RSI_H15  RSI_H16  RSI_H17  UP_DOWN  \n",
       "0      0.0      0.0      0.0        0  \n",
       "1      0.0      0.0      0.0        0  \n",
       "2      0.0      0.0      0.0        0  \n",
       "3      0.0      0.0      0.0        0  \n",
       "4      0.0      0.0      0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4620 entries, 0 to 4619\n",
      "Data columns (total 61 columns):\n",
      "Date        4620 non-null object\n",
      "Open        4620 non-null float64\n",
      "High        4620 non-null float64\n",
      "Low         4620 non-null float64\n",
      "Close       4620 non-null float64\n",
      "Volume_n    4620 non-null float64\n",
      "Volume_m    4620 non-null float64\n",
      "return      4620 non-null float64\n",
      "PE          4620 non-null float64\n",
      "RR          4620 non-null float64\n",
      "RR_H        4620 non-null float64\n",
      "RR_V        4620 non-null float64\n",
      "RSI2        4620 non-null float64\n",
      "RSI3        4620 non-null float64\n",
      "RSI4        4620 non-null float64\n",
      "RSI5        4620 non-null float64\n",
      "RSI6        4620 non-null float64\n",
      "RSI7        4620 non-null float64\n",
      "RSI8        4620 non-null float64\n",
      "RSI9        4620 non-null float64\n",
      "RSI10       4620 non-null float64\n",
      "RSI11       4620 non-null float64\n",
      "RSI12       4620 non-null float64\n",
      "RSI13       4620 non-null float64\n",
      "RSI14       4620 non-null float64\n",
      "RSI15       4620 non-null float64\n",
      "RSI16       4620 non-null float64\n",
      "RSI17       4620 non-null float64\n",
      "RSI_V2      4620 non-null float64\n",
      "RSI_V3      4620 non-null float64\n",
      "RSI_V4      4620 non-null float64\n",
      "RSI_V5      4620 non-null float64\n",
      "RSI_V6      4620 non-null float64\n",
      "RSI_V7      4620 non-null float64\n",
      "RSI_V8      4620 non-null float64\n",
      "RSI_V9      4620 non-null float64\n",
      "RSI_V10     4620 non-null float64\n",
      "RSI_V11     4620 non-null float64\n",
      "RSI_V12     4620 non-null float64\n",
      "RSI_V13     4620 non-null float64\n",
      "RSI_V14     4620 non-null float64\n",
      "RSI_V15     4620 non-null float64\n",
      "RSI_V16     4620 non-null float64\n",
      "RSI_V17     4620 non-null float64\n",
      "RSI_H2      4620 non-null float64\n",
      "RSI_H3      4620 non-null float64\n",
      "RSI_H4      4620 non-null float64\n",
      "RSI_H5      4620 non-null float64\n",
      "RSI_H6      4620 non-null float64\n",
      "RSI_H7      4620 non-null float64\n",
      "RSI_H8      4620 non-null float64\n",
      "RSI_H9      4620 non-null float64\n",
      "RSI_H10     4620 non-null float64\n",
      "RSI_H11     4620 non-null float64\n",
      "RSI_H12     4620 non-null float64\n",
      "RSI_H13     4620 non-null float64\n",
      "RSI_H14     4620 non-null float64\n",
      "RSI_H15     4620 non-null float64\n",
      "RSI_H16     4620 non-null float64\n",
      "RSI_H17     4620 non-null float64\n",
      "UP_DOWN     4620 non-null int64\n",
      "dtypes: float64(59), int64(1), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def UP_DOWN(data):\n",
    "    data_day_number = range(data['Date'].size)\n",
    "    tmpList = []\n",
    "    \n",
    "    for item in data_day_number:\n",
    "        spread = data['Close'][item] - data['Open'][item]\n",
    "        if spread > 0 :\n",
    "            tmp = 1\n",
    "        elif spread <= 0:\n",
    "            tmp = 0\n",
    " \n",
    "        tmpList.append(tmp)\n",
    "    \n",
    "    tmpSeries = pd.Series(tmpList)\n",
    "    data['UP_DOWN']=tmpSeries\n",
    "UP_DOWN(data)\n",
    "\n",
    "data1 = data.drop(['Date', 'Open', 'High','Low','Close','Volume_n','Volume_m','return','PE','RR','RR_V','RR_H'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4620 entries, 0 to 4619\n",
      "Data columns (total 49 columns):\n",
      "RSI2       4620 non-null float64\n",
      "RSI3       4620 non-null float64\n",
      "RSI4       4620 non-null float64\n",
      "RSI5       4620 non-null float64\n",
      "RSI6       4620 non-null float64\n",
      "RSI7       4620 non-null float64\n",
      "RSI8       4620 non-null float64\n",
      "RSI9       4620 non-null float64\n",
      "RSI10      4620 non-null float64\n",
      "RSI11      4620 non-null float64\n",
      "RSI12      4620 non-null float64\n",
      "RSI13      4620 non-null float64\n",
      "RSI14      4620 non-null float64\n",
      "RSI15      4620 non-null float64\n",
      "RSI16      4620 non-null float64\n",
      "RSI17      4620 non-null float64\n",
      "RSI_V2     4620 non-null float64\n",
      "RSI_V3     4620 non-null float64\n",
      "RSI_V4     4620 non-null float64\n",
      "RSI_V5     4620 non-null float64\n",
      "RSI_V6     4620 non-null float64\n",
      "RSI_V7     4620 non-null float64\n",
      "RSI_V8     4620 non-null float64\n",
      "RSI_V9     4620 non-null float64\n",
      "RSI_V10    4620 non-null float64\n",
      "RSI_V11    4620 non-null float64\n",
      "RSI_V12    4620 non-null float64\n",
      "RSI_V13    4620 non-null float64\n",
      "RSI_V14    4620 non-null float64\n",
      "RSI_V15    4620 non-null float64\n",
      "RSI_V16    4620 non-null float64\n",
      "RSI_V17    4620 non-null float64\n",
      "RSI_H2     4620 non-null float64\n",
      "RSI_H3     4620 non-null float64\n",
      "RSI_H4     4620 non-null float64\n",
      "RSI_H5     4620 non-null float64\n",
      "RSI_H6     4620 non-null float64\n",
      "RSI_H7     4620 non-null float64\n",
      "RSI_H8     4620 non-null float64\n",
      "RSI_H9     4620 non-null float64\n",
      "RSI_H10    4620 non-null float64\n",
      "RSI_H11    4620 non-null float64\n",
      "RSI_H12    4620 non-null float64\n",
      "RSI_H13    4620 non-null float64\n",
      "RSI_H14    4620 non-null float64\n",
      "RSI_H15    4620 non-null float64\n",
      "RSI_H16    4620 non-null float64\n",
      "RSI_H17    4620 non-null float64\n",
      "UP_DOWN    4620 non-null int64\n",
      "dtypes: float64(48), int64(1)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UP_DOWN'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = data1.columns.tolist()\n",
    "cols[48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = data1.fillna(-1)\n",
    "cols = data1.columns.tolist()\n",
    "#cols[32]\n",
    "data1 = data1[[cols[48]] + cols[0:47]]\n",
    "n = len(data['Date'])/5\n",
    "m = len(data['Date']) - n\n",
    "train_data = data1.iloc[:m,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3696 entries, 0 to 3695\n",
      "Data columns (total 48 columns):\n",
      "UP_DOWN    3696 non-null int64\n",
      "RSI2       3696 non-null float64\n",
      "RSI3       3696 non-null float64\n",
      "RSI4       3696 non-null float64\n",
      "RSI5       3696 non-null float64\n",
      "RSI6       3696 non-null float64\n",
      "RSI7       3696 non-null float64\n",
      "RSI8       3696 non-null float64\n",
      "RSI9       3696 non-null float64\n",
      "RSI10      3696 non-null float64\n",
      "RSI11      3696 non-null float64\n",
      "RSI12      3696 non-null float64\n",
      "RSI13      3696 non-null float64\n",
      "RSI14      3696 non-null float64\n",
      "RSI15      3696 non-null float64\n",
      "RSI16      3696 non-null float64\n",
      "RSI17      3696 non-null float64\n",
      "RSI_V2     3696 non-null float64\n",
      "RSI_V3     3696 non-null float64\n",
      "RSI_V4     3696 non-null float64\n",
      "RSI_V5     3696 non-null float64\n",
      "RSI_V6     3696 non-null float64\n",
      "RSI_V7     3696 non-null float64\n",
      "RSI_V8     3696 non-null float64\n",
      "RSI_V9     3696 non-null float64\n",
      "RSI_V10    3696 non-null float64\n",
      "RSI_V11    3696 non-null float64\n",
      "RSI_V12    3696 non-null float64\n",
      "RSI_V13    3696 non-null float64\n",
      "RSI_V14    3696 non-null float64\n",
      "RSI_V15    3696 non-null float64\n",
      "RSI_V16    3696 non-null float64\n",
      "RSI_V17    3696 non-null float64\n",
      "RSI_H2     3696 non-null float64\n",
      "RSI_H3     3696 non-null float64\n",
      "RSI_H4     3696 non-null float64\n",
      "RSI_H5     3696 non-null float64\n",
      "RSI_H6     3696 non-null float64\n",
      "RSI_H7     3696 non-null float64\n",
      "RSI_H8     3696 non-null float64\n",
      "RSI_H9     3696 non-null float64\n",
      "RSI_H10    3696 non-null float64\n",
      "RSI_H11    3696 non-null float64\n",
      "RSI_H12    3696 non-null float64\n",
      "RSI_H13    3696 non-null float64\n",
      "RSI_H14    3696 non-null float64\n",
      "RSI_H15    3696 non-null float64\n",
      "RSI_H16    3696 non-null float64\n",
      "dtypes: float64(47), int64(1)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "import time \n",
    "sql_sc = SQLContext(sc)\n",
    "train_data.iloc[:(m/5),:]\n",
    "train_data.iloc[(m/5):(2*m/5),:]\n",
    "train_data.iloc[(2*m/5):(3*m/5),:]\n",
    "train_data.iloc[(3*m/5):(5*m/5),:]\n",
    "train_data.iloc[(4*m/5):m,:]\n",
    "\n",
    "cross_data_list = [i for i in range(1,6)]\n",
    "cross_data_list[0] = train_data.iloc[:(m/5),:]\n",
    "cross_data_list[1] = train_data.iloc[(m/5):(2*m/5),:]\n",
    "cross_data_list[2] = train_data.iloc[(2*m/5):(3*m/5),:]\n",
    "cross_data_list[3] = train_data.iloc[(3*m/5):(5*m/5),:]\n",
    "cross_data_list[4] = train_data.iloc[(4*m/5):m,:]\n",
    "cross_data_pandas = [i for i in range(1,6)]\n",
    "for i in range(0,5,1):\n",
    "    cross_data_pandas[i] = pd.DataFrame(cross_data_list[i])\n",
    "#cross_data_pandas[4]\n",
    "\n",
    "cross_sql = [i for i in range(1,6)]\n",
    "for i in range(0,5,1):\n",
    "    cross_sql[i] = sql_sc.createDataFrame(cross_data_pandas[i])\n",
    "\n",
    "\n",
    "assembler1 = VectorAssembler(inputCols=[\"RSI2\",\"RSI3\",\"RSI4\",\"RSI5\",\"RSI6\",\"RSI7\",\"RSI8\"\n",
    "                                       ,\"RSI9\",\"RSI10\",\"RSI11\",\"RSI12\",\"RSI13\",\"RSI14\",\"RSI15\"\n",
    "                                       ,\"RSI17\",\"RSI_V2\",\"RSI_V3\",\"RSI_V4\",\"RSI_V5\",\"RSI_V6\"\n",
    "                                       ,\"RSI_V7\",\"RSI_V8\",\"RSI_V9\",\"RSI_V10\",\"RSI_V11\",\"RSI_V12\"\n",
    "                                       ,\"RSI_V13\",\"RSI_V14\",\"RSI_V15\",\"RSI_V16\",\"RSI_H2\",\"RSI_H3\"\n",
    "                                       ,\"RSI_H4\",\"RSI_H5\",\"RSI_H6\",\"RSI_H7\",\"RSI_H8\",\"RSI_H9\"\n",
    "                                       ,\"RSI_H10\",\"RSI_H11\",\"RSI_H12\",\"RSI_H13\",\"RSI_H14\",\"RSI_H15\"\n",
    "                                       ,\"RSI_H16\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparametr tuning cross validation 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error(0) = 0.435865\n",
      "Test Error(1) = 0.519021\n",
      "Test Error(2) = 0.568683\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-c3470b455b73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;31m# Chain indexers and forest in a Pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabelIndexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatureIndexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_sql\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_sql\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"indexedLabel\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictionCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, metricName=\"accuracy\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/spark/python/pyspark/ml/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m/usr/local/spark/python/pyspark/ml/pipeline.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    211\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# must be an Estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/spark/python/pyspark/ml/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m/usr/local/spark/python/pyspark/ml/wrapper.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/spark/python/pyspark/ml/wrapper.pyc\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m    813\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32m/usr/local/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_give_back_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[1;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bigdatas16/anaconda2/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    432\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m                         \u001b[1;32mwhile\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m                             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "import time \n",
    "sql_sc = SQLContext(sc)\n",
    "train_data.iloc[:(m/5),:]\n",
    "train_data.iloc[(m/5):(2*m/5),:]\n",
    "train_data.iloc[(2*m/5):(3*m/5),:]\n",
    "train_data.iloc[(3*m/5):(5*m/5),:]\n",
    "train_data.iloc[(4*m/5):m,:]\n",
    "\n",
    "cross_data_list = [i for i in range(1,6)]\n",
    "cross_data_list[0] = train_data.iloc[:(m/5),:]\n",
    "cross_data_list[1] = train_data.iloc[(m/5):(2*m/5),:]\n",
    "cross_data_list[2] = train_data.iloc[(2*m/5):(3*m/5),:]\n",
    "cross_data_list[3] = train_data.iloc[(3*m/5):(5*m/5),:]\n",
    "cross_data_list[4] = train_data.iloc[(4*m/5):m,:]\n",
    "cross_data_pandas = [i for i in range(1,6)]\n",
    "for i in range(0,5,1):\n",
    "    cross_data_pandas[i] = pd.DataFrame(cross_data_list[i])\n",
    "#cross_data_pandas[4]\n",
    "\n",
    "cross_sql = [i for i in range(1,6)]\n",
    "for i in range(0,5,1):\n",
    "    cross_sql[i] = sql_sc.createDataFrame(cross_data_pandas[i])\n",
    "\n",
    "\n",
    "assembler1 = VectorAssembler(inputCols=[\"RSI2\",\"RSI3\",\"RSI4\",\"RSI5\",\"RSI6\",\"RSI7\",\"RSI8\"\n",
    "                                       ,\"RSI9\",\"RSI10\",\"RSI11\",\"RSI12\",\"RSI13\",\"RSI14\",\"RSI15\"\n",
    "                                       ,\"RSI17\",\"RSI_V2\",\"RSI_V3\",\"RSI_V4\",\"RSI_V5\",\"RSI_V6\"\n",
    "                                       ,\"RSI_V7\",\"RSI_V8\",\"RSI_V9\",\"RSI_V10\",\"RSI_V11\",\"RSI_V12\"\n",
    "                                       ,\"RSI_V13\",\"RSI_V14\",\"RSI_V15\",\"RSI_V16\",\"RSI_H2\",\"RSI_H3\"\n",
    "                                       ,\"RSI_H4\",\"RSI_H5\",\"RSI_H6\",\"RSI_H7\",\"RSI_H8\",\"RSI_H9\"\n",
    "                                       ,\"RSI_H10\",\"RSI_H11\",\"RSI_H12\",\"RSI_H13\",\"RSI_H14\",\"RSI_H15\"\n",
    "                                       ,\"RSI_H16\"], outputCol=\"features\")\n",
    "for i in range(0,5,1):\n",
    "    cross_sql[i] = assembler1.transform(cross_sql[i])\n",
    "    \n",
    "frames = [i for i in range(1,6)]\n",
    "for i in range(0,5):\n",
    "    #print(i)\n",
    "    frames[i] = pd.concat([cross_data_pandas[(i+1)%5],cross_data_pandas[(i+2)%5],cross_data_pandas[(i+3)%5],cross_data_pandas[(i+4)%5]])\n",
    "    result_sql = [i for i in range(1,6)]\n",
    "\n",
    "for i in range(0,5):   \n",
    "    result_sql[i] = sql_sc.createDataFrame(frames[i])   \n",
    "    \n",
    "assembler1 = VectorAssembler(inputCols=[\"RSI2\",\"RSI3\",\"RSI4\",\"RSI5\",\"RSI6\",\"RSI7\",\"RSI8\"\n",
    "                                       ,\"RSI9\",\"RSI10\",\"RSI11\",\"RSI12\",\"RSI13\",\"RSI14\",\"RSI15\"\n",
    "                                       ,\"RSI17\",\"RSI_V2\",\"RSI_V3\",\"RSI_V4\",\"RSI_V5\",\"RSI_V6\"\n",
    "                                       ,\"RSI_V7\",\"RSI_V8\",\"RSI_V9\",\"RSI_V10\",\"RSI_V11\",\"RSI_V12\"\n",
    "                                       ,\"RSI_V13\",\"RSI_V14\",\"RSI_V15\",\"RSI_V16\",\"RSI_H2\",\"RSI_H3\"\n",
    "                                       ,\"RSI_H4\",\"RSI_H5\",\"RSI_H6\",\"RSI_H7\",\"RSI_H8\",\"RSI_H9\"\n",
    "                                       ,\"RSI_H10\",\"RSI_H11\",\"RSI_H12\",\"RSI_H13\",\"RSI_H14\",\"RSI_H15\"\n",
    "                                       ,\"RSI_H16\"],outputCol=\"features\")\n",
    "for i in range(0,5):  \n",
    "    result_sql[i] = assembler1.transform(result_sql[i])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "cv5_test_error = []    \n",
    "numTrees_maxDepth = []    \n",
    "for j in range(1,7,1):\n",
    "    for k in range(1,21,1):\n",
    "        Test_Error = []\n",
    "        for i in range(0,5):\n",
    "            labelIndexer = StringIndexer(inputCol = \"UP_DOWN\", outputCol=\"indexedLabel\").fit(result_sql[i])\n",
    "            featureIndexer = VectorIndexer(inputCol = \"features\", outputCol=\"indexedFeatures\").fit(result_sql[i])\n",
    "            #rf = RandomForestClassifier(labelCol=\"labelIndexer\", featuresCol=\"features\")\n",
    "            rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",numTrees = k,maxDepth = j)\n",
    "            # Chain indexers and forest in a Pipeline\n",
    "            pipeline = Pipeline(stages=[labelIndexer,featureIndexer,rf])\n",
    "            model = pipeline.fit(result_sql[i])\n",
    "            predictions = model.transform(cross_sql[i])\n",
    "            evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\")#, metricName=\"accuracy\")\n",
    "            accuracy = evaluator.evaluate(predictions)\n",
    "            print(\"Test Error(%d) = %g\" % (i,1.0 - accuracy))\n",
    "            Test_Error.append(1.0 - accuracy)\n",
    "        cv5_test_error.append(mean(Test_Error))\n",
    "        numTrees_maxDepth.append([i,j])\n",
    "\n",
    "end = time.time()\n",
    "print \"Cross Validation 5 Folds Hyperparameter Tuning : Time taken = %f second\"%(end - start)\n",
    "        \n",
    "mintest = np.min(cv5_test_error)\n",
    "c = []\n",
    "for i in range(len(cv5_test_error)):\n",
    "    c.append(np.min(cv5_test_error) == cv5_test_error[i])\n",
    "    \n",
    "for i in range(len(cv5_test_error)):    \n",
    "    if c[i] == True:\n",
    "        print(numTrees_maxDepth[i],mintest)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45951797951749107"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data1.iloc[:m,:]\n",
    "train_sql = sql_sc.createDataFrame(train_data)\n",
    "test_data = data1.iloc[m:,:]\n",
    "test_sql = sql_sc.createDataFrame(test_data)\n",
    "\n",
    "assembler1 = VectorAssembler(inputCols=[\"RSI2\",\"RSI3\",\"RSI4\",\"RSI5\",\"RSI6\",\"RSI7\",\"RSI8\"\n",
    "                                       ,\"RSI9\",\"RSI10\",\"RSI11\",\"RSI12\",\"RSI13\",\"RSI14\",\"RSI15\"\n",
    "                                       ,\"RSI17\",\"RSI_V2\",\"RSI_V3\",\"RSI_V4\",\"RSI_V5\",\"RSI_V6\"\n",
    "                                       ,\"RSI_V7\",\"RSI_V8\",\"RSI_V9\",\"RSI_V10\",\"RSI_V11\",\"RSI_V12\"\n",
    "                                       ,\"RSI_V13\",\"RSI_V14\",\"RSI_V15\",\"RSI_V16\",\"RSI_H2\",\"RSI_H3\"\n",
    "                                       ,\"RSI_H4\",\"RSI_H5\",\"RSI_H6\",\"RSI_H7\",\"RSI_H8\",\"RSI_H9\"\n",
    "                                       ,\"RSI_H10\",\"RSI_H11\",\"RSI_H12\",\"RSI_H13\",\"RSI_H14\",\"RSI_H15\"\n",
    "                                       ,\"RSI_H16\"],outputCol=\"features\")\n",
    "train_sql = assembler1.transform(train_sql)\n",
    "labelIndexer = StringIndexer(inputCol = \"UP_DOWN\", outputCol=\"indexedLabel\").fit(train_sql)\n",
    "featureIndexer = VectorIndexer(inputCol = \"features\", outputCol=\"indexedFeatures\").fit(train_sql)\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",numTrees = 4,maxDepth = 6)\n",
    "pipeline = Pipeline(stages=[labelIndexer,featureIndexer,rf])\n",
    "model = pipeline.fit(train_sql)\n",
    "assembler = VectorAssembler(inputCols=[\"RSI2\",\"RSI3\",\"RSI4\",\"RSI5\",\"RSI6\",\"RSI7\",\"RSI8\"\n",
    "                                       ,\"RSI9\",\"RSI10\",\"RSI11\",\"RSI12\",\"RSI13\",\"RSI14\",\"RSI15\"\n",
    "                                       ,\"RSI17\",\"RSI_V2\",\"RSI_V3\",\"RSI_V4\",\"RSI_V5\",\"RSI_V6\"\n",
    "                                       ,\"RSI_V7\",\"RSI_V8\",\"RSI_V9\",\"RSI_V10\",\"RSI_V11\",\"RSI_V12\"\n",
    "                                       ,\"RSI_V13\",\"RSI_V14\",\"RSI_V15\",\"RSI_V16\",\"RSI_H2\",\"RSI_H3\"\n",
    "                                       ,\"RSI_H4\",\"RSI_H5\",\"RSI_H6\",\"RSI_H7\",\"RSI_H8\",\"RSI_H9\"\n",
    "                                       ,\"RSI_H10\",\"RSI_H11\",\"RSI_H12\",\"RSI_H13\",\"RSI_H14\",\"RSI_H15\"\n",
    "                                       ,\"RSI_H16\"],outputCol=\"features\")\n",
    "test_sql = assembler.transform(test_sql)\n",
    "predictions = model.transform(test_sql)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\")#, metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
